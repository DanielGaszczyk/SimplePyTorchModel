{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2174e876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fae376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fe5b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a568153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2375, 0.4304, 0.9713, 0.4366, 0.6763],\n",
      "        [0.1278, 0.6120, 0.3879, 0.1423, 0.5027]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c7a90d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2375, 0.4304, 0.9713, 0.4366, 0.6763, 0.1278, 0.6120, 0.3879, 0.1423,\n",
       "         0.5027]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to flatten y before puttin in neural network\n",
    "y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f674ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2375, 0.4304, 0.9713, 0.4366, 0.6763, 0.1278, 0.6120, 0.3879, 0.1423,\n",
       "         0.5027]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to reasign view, because before that y looking like [2,5]\n",
    "y = y.view([1,10])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3621dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "945e0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", \n",
    "                       train = True, \n",
    "                       download = True, \n",
    "                       transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", \n",
    "                       train = False, \n",
    "                       download = True, \n",
    "                       transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d76e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5cf77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 2, 7, 6, 5, 8, 0, 5, 9, 7])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a2fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e8ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a726b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28,28))\n",
    "# We changed shape from [1,28,28] to [28,28] (Normal image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bbaca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)\n",
    "# Shaping is very important, with normal image we will get something like [28,28], \n",
    "# but this first '1' is crucial for DL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4771c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "# Checking if we have balanced data\n",
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e461ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:9.871666666666666\n",
      "1:11.236666666666666\n",
      "2:9.93\n",
      "3:10.218333333333334\n",
      "4:9.736666666666666\n",
      "5:9.035\n",
      "6:9.863333333333333\n",
      "7:10.441666666666666\n",
      "8:9.751666666666667\n",
      "9:9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "# Calculating percent of given number in dataset\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}:{counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bca5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1e77666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()               # If we forgot about that line we get error : \n",
    "                                         # 'AttributeError: cannot assign module before Module.__init__() call'\n",
    "            \n",
    "        self.fc1 = nn.Linear(784, 64)    # (Input, output) - Input is 784, because 28*28, output is 64\n",
    "                                         # Input is our flattened image, output is whatever we want\n",
    "                                         # For convolution we get nn.Conv instead\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)     # 10 in output because we get ten classes - 0,1,2,...,9\n",
    "            \n",
    "    def forward(self, x):                # Connection between layers\n",
    "                                         # We can throw here more complex logic to build more advanced models\n",
    "                                         # we can put here like if - else etc. we can also put different type\n",
    "                                         # of layers like some visual layers and next some text layers.\n",
    "            \n",
    "        x = F.relu(self.fc1(x))          # relu - rectified linear - activation function ( in this example \n",
    "                                         # over entire layer)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim = 1) # dim = 1 - what we want to sum to one (across axis 1 - actual output layer)\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3650d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4447, -2.3930, -2.3541, -2.1690, -2.3404, -2.1950, -2.2355, -2.3250,\n",
       "         -2.3934, -2.2170]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))            # Sample data for test\n",
    "output = net(X.view(-1,28*28))     # Passing data through NN, with data forming to flat 28x28\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef88b435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0281, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) # If lr too big, or to small we can't get perfect result\n",
    "\n",
    "EPOCHS = 3                                           # Number of full runs on ours dataset\n",
    "\n",
    "for epoch in range (EPOCHS):\n",
    "    for data in trainset:                            # data is a batch of features and labels         \n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d867fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.979\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2b29cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfbe9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
